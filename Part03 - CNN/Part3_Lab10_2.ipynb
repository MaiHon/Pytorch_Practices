{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init as init\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    gpu_num = 1\n",
    "    torch.cuda.set_device(gpu_num)\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "    print(torch.cuda.get_device_properties(gpu_num).name, 'is Ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .001\n",
    "training_epochs = 5\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test  = dsets.MNIST(root='MNIST_data/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader = DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc = nn.Linear(7*7*64, 10, bias=True)\n",
    "        init.xavier_uniform_(self.fc.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Model(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (flatten): Flatten()\n",
       "  (fc): Linear(in_features=3136, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN_Model().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.223937914\n",
      "[Epoch:    2] cost = 0.0620741434\n",
      "[Epoch:    3] cost = 0.0448859222\n",
      "[Epoch:    4] cost = 0.0356147848\n",
      "[Epoch:    5] cost = 0.029051125\n",
      "Learning Finished\n",
      "Time Taken 252.756209s by cpu\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "total_batch = len(data_loader)\n",
    "\n",
    "import time\n",
    "s = time.time()\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for x, y in data_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        hypothesis = model(x)\n",
    "        cost = criterion(hypothesis, y)\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "    \n",
    "    # clear_output(wait=True)\n",
    "    print(\"[Epoch: {:>4}] cost = {:>.9}\".format(epoch + 1, avg_cost))\n",
    "    \n",
    "print(\"Learning Finished\")\n",
    "print(\"Time Taken {:.6f}s by {}\".format(time.time()-s, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9855999946594238\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.0.weight',\n",
       "              tensor([[[[-0.2847,  0.0263, -0.0059],\n",
       "                        [-0.0308,  0.3160,  0.3241],\n",
       "                        [ 0.2061,  0.0612,  0.2742]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2149, -0.0971,  0.1298],\n",
       "                        [-0.2361,  0.1569,  0.2311],\n",
       "                        [ 0.4090,  0.3588, -0.0739]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3047,  0.3221,  0.3196],\n",
       "                        [-0.1408, -0.0066, -0.1317],\n",
       "                        [ 0.3348,  0.3306,  0.3071]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0763, -0.3314, -0.1929],\n",
       "                        [-0.0334,  0.1300,  0.0744],\n",
       "                        [ 0.4052,  0.0014,  0.3730]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3429,  0.1797, -0.0768],\n",
       "                        [ 0.1020, -0.1271, -0.1568],\n",
       "                        [ 0.3253,  0.4010, -0.3728]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.4539, -0.0654, -0.1190],\n",
       "                        [-0.1862,  0.0171,  0.4047],\n",
       "                        [-0.2363, -0.0522,  0.3519]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2702,  0.3277, -0.2136],\n",
       "                        [ 0.1859,  0.4268,  0.1004],\n",
       "                        [ 0.1773, -0.2479, -0.1297]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1774,  0.2251,  0.3607],\n",
       "                        [ 0.0952, -0.3001, -0.1352],\n",
       "                        [-0.0341, -0.1546, -0.2745]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1065, -0.4887, -0.3310],\n",
       "                        [ 0.5887, -0.0882, -0.1838],\n",
       "                        [ 0.2640,  0.1282,  0.3091]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2864,  0.1529,  0.2903],\n",
       "                        [ 0.3123, -0.2337,  0.1594],\n",
       "                        [ 0.4003,  0.3326,  0.3127]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3234, -0.2437,  0.2657],\n",
       "                        [ 0.3675,  0.4002,  0.2693],\n",
       "                        [ 0.3165,  0.3210,  0.1930]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2998,  0.0924, -0.2265],\n",
       "                        [ 0.0515, -0.0824,  0.0658],\n",
       "                        [ 0.1987, -0.3423, -0.4404]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1849,  0.2067,  0.4039],\n",
       "                        [-0.1800, -0.1827,  0.2546],\n",
       "                        [-0.4193, -0.2486, -0.1286]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1443,  0.1753, -0.2536],\n",
       "                        [-0.1633,  0.2943,  0.4134],\n",
       "                        [ 0.2184,  0.3680, -0.1039]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0928,  0.4246,  0.3290],\n",
       "                        [ 0.2980, -0.0613,  0.2246],\n",
       "                        [-0.5011, -0.2818,  0.1198]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2869, -0.1014,  0.1750],\n",
       "                        [ 0.3744, -0.1847,  0.1500],\n",
       "                        [ 0.2164, -0.1882,  0.2431]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3629, -0.1701,  0.2621],\n",
       "                        [-0.2401, -0.0601,  0.1700],\n",
       "                        [-0.3142,  0.0457,  0.5140]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2019, -0.0677,  0.2987],\n",
       "                        [-0.2444, -0.0802,  0.1334],\n",
       "                        [-0.1158,  0.0132,  0.4639]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1936, -0.2194, -0.1381],\n",
       "                        [ 0.2620, -0.1284, -0.4222],\n",
       "                        [ 0.1846, -0.0292,  0.3103]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1329, -0.0007,  0.3631],\n",
       "                        [ 0.2342,  0.3216,  0.1913],\n",
       "                        [ 0.1562,  0.1515, -0.1573]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0749, -0.2478, -0.2578],\n",
       "                        [-0.1842,  0.3248,  0.3500],\n",
       "                        [-0.0348,  0.3295,  0.3779]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.4043, -0.2168, -0.0815],\n",
       "                        [ 0.1815,  0.2949,  0.3037],\n",
       "                        [ 0.1547, -0.2762,  0.0959]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2175,  0.1728,  0.0788],\n",
       "                        [ 0.2856,  0.0374,  0.1136],\n",
       "                        [ 0.3724,  0.2683, -0.3566]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1371,  0.3293, -0.1672],\n",
       "                        [-0.0135,  0.4460, -0.3473],\n",
       "                        [ 0.1753, -0.1176, -0.1314]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3698, -0.2092, -0.0991],\n",
       "                        [ 0.1692, -0.2844,  0.1397],\n",
       "                        [-0.2008,  0.0755, -0.3721]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3799,  0.3738,  0.2118],\n",
       "                        [ 0.0197,  0.0863, -0.2944],\n",
       "                        [-0.3273, -0.4726, -0.3147]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1066,  0.5376,  0.3276],\n",
       "                        [-0.3436, -0.1084,  0.1352],\n",
       "                        [-0.3247, -0.2361,  0.1841]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2177, -0.0292,  0.2636],\n",
       "                        [-0.2624, -0.0877, -0.2128],\n",
       "                        [ 0.3013, -0.2558, -0.2173]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.4267,  0.4606,  0.2241],\n",
       "                        [ 0.1333, -0.0227, -0.1339],\n",
       "                        [-0.2169, -0.4272, -0.2118]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2867,  0.0401,  0.3274],\n",
       "                        [ 0.2644,  0.1215, -0.3564],\n",
       "                        [ 0.3614, -0.3682,  0.0182]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0008,  0.1998, -0.2997],\n",
       "                        [ 0.0286,  0.2609,  0.0794],\n",
       "                        [ 0.2848,  0.0365,  0.1323]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3738, -0.0025, -0.1075],\n",
       "                        [ 0.1704,  0.3495, -0.3516],\n",
       "                        [ 0.2659,  0.3047, -0.3754]]]], device='cuda:0')),\n",
       "             ('layer1.0.bias',\n",
       "              tensor([ 8.6842e-02, -1.3544e-04, -7.3224e-05,  2.4680e-01, -2.6556e-01,\n",
       "                       2.0985e-01,  1.9247e-01,  2.9845e-01, -5.7281e-04, -1.6081e-01,\n",
       "                       6.6218e-02,  3.4534e-01,  3.4855e-01, -4.5667e-02, -1.1553e-01,\n",
       "                       3.9983e-02, -8.3931e-02, -1.2604e-01,  3.8601e-02, -9.3352e-02,\n",
       "                       1.3483e-01, -5.5495e-03, -2.5785e-04, -3.6350e-02,  2.6525e-01,\n",
       "                       3.2635e-01, -4.5823e-02,  3.3807e-01, -1.4702e-01, -7.4668e-02,\n",
       "                       2.2658e-01,  2.4474e-01], device='cuda:0')),\n",
       "             ('layer2.0.weight',\n",
       "              tensor([[[[-0.0809, -0.0592, -0.0132],\n",
       "                        [ 0.0359, -0.0069,  0.0668],\n",
       "                        [ 0.0570,  0.0060,  0.0588]],\n",
       "              \n",
       "                       [[-0.0687, -0.0150, -0.0192],\n",
       "                        [-0.0713, -0.0415,  0.0172],\n",
       "                        [ 0.0492,  0.0570, -0.0043]],\n",
       "              \n",
       "                       [[-0.0362, -0.0112,  0.0801],\n",
       "                        [-0.0707, -0.0470,  0.0359],\n",
       "                        [ 0.0808,  0.0811,  0.0588]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0647, -0.0129, -0.0483],\n",
       "                        [-0.0186, -0.0482, -0.0674],\n",
       "                        [-0.0537,  0.0082, -0.0445]],\n",
       "              \n",
       "                       [[ 0.0069, -0.0683,  0.0558],\n",
       "                        [-0.0488,  0.0093,  0.0374],\n",
       "                        [ 0.0772,  0.0691,  0.0665]],\n",
       "              \n",
       "                       [[-0.0201,  0.0424,  0.0333],\n",
       "                        [-0.0091, -0.0524, -0.0413],\n",
       "                        [ 0.0304, -0.0011, -0.0214]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0418, -0.0361, -0.0766],\n",
       "                        [ 0.0142, -0.0954,  0.0323],\n",
       "                        [-0.0399,  0.0207,  0.0827]],\n",
       "              \n",
       "                       [[ 0.1105, -0.0251, -0.1118],\n",
       "                        [ 0.0765, -0.1345,  0.0121],\n",
       "                        [ 0.0362, -0.0381,  0.0672]],\n",
       "              \n",
       "                       [[ 0.0060,  0.0029, -0.0217],\n",
       "                        [ 0.0585, -0.0678, -0.0205],\n",
       "                        [ 0.0235, -0.1040, -0.0087]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1022,  0.0516,  0.0253],\n",
       "                        [ 0.0959,  0.0274, -0.0798],\n",
       "                        [ 0.0764,  0.0104, -0.0553]],\n",
       "              \n",
       "                       [[ 0.0133, -0.0292,  0.0147],\n",
       "                        [ 0.0352, -0.0112, -0.0097],\n",
       "                        [ 0.0078, -0.0245,  0.0224]],\n",
       "              \n",
       "                       [[ 0.0300,  0.0308,  0.0390],\n",
       "                        [ 0.0450,  0.0595, -0.0193],\n",
       "                        [ 0.0808, -0.0075, -0.0224]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0588,  0.0054, -0.0484],\n",
       "                        [ 0.0136, -0.0544, -0.0302],\n",
       "                        [ 0.0286, -0.0032, -0.0165]],\n",
       "              \n",
       "                       [[ 0.0375, -0.0427,  0.0333],\n",
       "                        [-0.0157, -0.0249, -0.0917],\n",
       "                        [ 0.0032, -0.1146, -0.0604]],\n",
       "              \n",
       "                       [[ 0.0761, -0.0129,  0.0656],\n",
       "                        [ 0.0472, -0.0064, -0.0177],\n",
       "                        [ 0.0564, -0.0570, -0.0263]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0806,  0.0634, -0.0205],\n",
       "                        [ 0.0309,  0.0712, -0.0230],\n",
       "                        [ 0.0831,  0.0036, -0.0515]],\n",
       "              \n",
       "                       [[ 0.0500,  0.0695, -0.0446],\n",
       "                        [ 0.0554,  0.0267,  0.0292],\n",
       "                        [ 0.0451, -0.0566,  0.0130]],\n",
       "              \n",
       "                       [[ 0.0180,  0.0446,  0.0159],\n",
       "                        [ 0.0221,  0.0659, -0.0461],\n",
       "                        [ 0.0672,  0.0196, -0.0458]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0067, -0.0180, -0.0577],\n",
       "                        [-0.0491,  0.0658,  0.0227],\n",
       "                        [ 0.1176,  0.0744,  0.1122]],\n",
       "              \n",
       "                       [[-0.0142, -0.0297, -0.1032],\n",
       "                        [-0.0486,  0.0354,  0.0721],\n",
       "                        [ 0.0579,  0.0400,  0.1056]],\n",
       "              \n",
       "                       [[-0.0766, -0.0632, -0.0661],\n",
       "                        [-0.0602,  0.0371,  0.0626],\n",
       "                        [-0.0112,  0.1195,  0.0942]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0154, -0.0082,  0.0193],\n",
       "                        [-0.0604, -0.0697, -0.0485],\n",
       "                        [-0.1012,  0.1515,  0.0831]],\n",
       "              \n",
       "                       [[-0.0679, -0.0304, -0.0290],\n",
       "                        [-0.0679, -0.0230,  0.0307],\n",
       "                        [ 0.0211,  0.0899,  0.0815]],\n",
       "              \n",
       "                       [[-0.0319,  0.0026, -0.0724],\n",
       "                        [-0.0981, -0.0471, -0.0762],\n",
       "                        [-0.0955, -0.0015,  0.0273]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0116,  0.0042,  0.0409],\n",
       "                        [-0.0283,  0.0183, -0.0126],\n",
       "                        [ 0.0237,  0.0329, -0.0089]],\n",
       "              \n",
       "                       [[ 0.0446,  0.0028,  0.0456],\n",
       "                        [ 0.0500, -0.0417, -0.0555],\n",
       "                        [-0.0614, -0.0557,  0.0221]],\n",
       "              \n",
       "                       [[ 0.0525, -0.0216, -0.0010],\n",
       "                        [-0.0187, -0.0221,  0.0078],\n",
       "                        [-0.0420, -0.0353,  0.0215]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0075,  0.0555, -0.0617],\n",
       "                        [-0.0361, -0.0167, -0.0236],\n",
       "                        [ 0.0112,  0.0150,  0.0248]],\n",
       "              \n",
       "                       [[-0.0581, -0.0551, -0.0296],\n",
       "                        [ 0.0145,  0.0024, -0.0552],\n",
       "                        [-0.0356,  0.0102, -0.0536]],\n",
       "              \n",
       "                       [[-0.0120, -0.0466,  0.0202],\n",
       "                        [ 0.0493,  0.0054, -0.0268],\n",
       "                        [ 0.0080, -0.0261,  0.0282]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0044, -0.0780, -0.0654],\n",
       "                        [-0.0778, -0.0081, -0.0327],\n",
       "                        [ 0.0239,  0.0725,  0.0511]],\n",
       "              \n",
       "                       [[ 0.0406,  0.0097, -0.0585],\n",
       "                        [ 0.0551,  0.0911,  0.0508],\n",
       "                        [ 0.0568,  0.0213, -0.0112]],\n",
       "              \n",
       "                       [[ 0.0375,  0.0455, -0.0669],\n",
       "                        [-0.0182,  0.0644,  0.0541],\n",
       "                        [-0.0187, -0.0475,  0.0352]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0685, -0.0209, -0.0068],\n",
       "                        [-0.0252, -0.1113, -0.0017],\n",
       "                        [ 0.0071,  0.0020,  0.0172]],\n",
       "              \n",
       "                       [[ 0.0275,  0.0246, -0.0214],\n",
       "                        [-0.0215,  0.0042,  0.0235],\n",
       "                        [ 0.0216,  0.0692,  0.0301]],\n",
       "              \n",
       "                       [[-0.0051, -0.0124,  0.0452],\n",
       "                        [-0.0281, -0.0291, -0.0168],\n",
       "                        [-0.0197, -0.0584,  0.0002]]]], device='cuda:0')),\n",
       "             ('layer2.0.bias',\n",
       "              tensor([ 2.6550e-03, -7.9377e-03,  1.2490e-02, -1.2015e-02, -4.5292e-02,\n",
       "                      -7.2823e-02, -4.3497e-02, -5.6853e-02,  1.8101e-02, -6.8052e-03,\n",
       "                      -2.5812e-02, -3.1724e-02,  1.5373e-02, -1.8413e-02, -6.8483e-02,\n",
       "                      -6.6342e-05, -1.9896e-04, -4.5996e-02, -3.6175e-02,  4.4972e-02,\n",
       "                       3.8041e-02, -4.8136e-02,  3.6709e-02, -5.0881e-02, -5.8617e-02,\n",
       "                       7.2673e-03, -5.0333e-02,  5.3073e-02, -6.4546e-03,  4.4947e-02,\n",
       "                       2.1766e-02, -4.8141e-02,  2.6501e-02, -6.4720e-02, -1.8112e-02,\n",
       "                      -1.9221e-02, -6.9764e-02, -7.0592e-02, -4.8567e-02,  4.1538e-02,\n",
       "                      -5.8769e-02, -2.4114e-02,  5.1308e-02,  5.2181e-02, -6.1215e-02,\n",
       "                       4.1011e-02, -5.0562e-02, -1.9715e-02, -7.9863e-03,  1.8244e-03,\n",
       "                      -2.8411e-02, -1.6409e-02, -7.0692e-02,  3.7077e-02, -1.5787e-02,\n",
       "                      -3.7982e-02, -5.7202e-02, -3.2220e-02,  1.2920e-02, -1.2755e-02,\n",
       "                      -4.5693e-02,  4.2883e-02, -3.6827e-03,  2.8468e-02], device='cuda:0')),\n",
       "             ('fc.weight',\n",
       "              tensor([[-4.4786e-02, -3.9951e-02, -1.8699e-02,  ...,  2.5770e-03,\n",
       "                       -3.1252e-02, -3.0979e-03],\n",
       "                      [ 2.7699e-02, -1.7487e-02,  2.6282e-02,  ...,  2.3115e-02,\n",
       "                       -6.0329e-04,  2.2632e-02],\n",
       "                      [ 1.8030e-02,  3.4235e-03, -3.1755e-03,  ...,  8.6977e-03,\n",
       "                       -4.8987e-05,  2.5698e-02],\n",
       "                      ...,\n",
       "                      [-2.4721e-02, -4.1180e-02, -1.5081e-02,  ...,  7.3329e-03,\n",
       "                        4.2121e-03,  4.2987e-03],\n",
       "                      [-5.7516e-04,  2.7810e-02, -5.0116e-03,  ..., -3.5058e-02,\n",
       "                        8.2930e-03,  1.6263e-02],\n",
       "                      [ 2.0139e-04, -2.7621e-02, -2.9689e-02,  ...,  1.4277e-02,\n",
       "                        2.7825e-02,  3.8782e-02]], device='cuda:0')),\n",
       "             ('fc.bias',\n",
       "              tensor([ 0.0111,  0.0018, -0.0103,  0.0087, -0.0042,  0.0160,  0.0106, -0.0140,\n",
       "                      -0.0020,  0.0001], device='cuda:0'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 32, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([10, 3136])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50186"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\workspace\\Pytorch\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type CNN_Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, './CNN_Module.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./CNN_Module.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, ceil_mode=True)\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(4*4*128, 625)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(625, 10)\n",
    "        \n",
    "        init.xavier_uniform_(self.fc1.weight)\n",
    "        init.xavier_uniform_(self.fc2.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Model(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (flatten): Flatten()\n",
      "  (fc1): Linear(in_features=2048, out_features=625, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=625, out_features=10, bias=True)\n",
      ")\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "\n",
    "value = torch.Tensor(1, 1, 28, 28).to(device)\n",
    "print(model(value).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    import time\n",
    "    s = time.time()\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "\n",
    "        for x, y in data_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            hypothesis = model(x)\n",
    "            cost = criterion(hypothesis, y)\n",
    "            optimizer.zero_grad()\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_cost += cost / total_batch\n",
    "\n",
    "        # clear_output(wait=True)\n",
    "        print(\"[Epoch: {:>4}] cost = {:>.9}\".format(epoch + 1, avg_cost))\n",
    "\n",
    "    print(\"Learning Finished\")\n",
    "    print(\"Time Taken {:.6f}s by {}\".format(time.time()-s, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.152267739\n",
      "[Epoch:    2] cost = 0.0406920612\n",
      "[Epoch:    3] cost = 0.0291638579\n",
      "[Epoch:    4] cost = 0.0220566411\n",
      "[Epoch:    5] cost = 0.0163107142\n",
      "Learning Finished\n",
      "Time Taken 460.846869s by cpu\n",
      "7min 40s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 1 train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1379557"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/honeyeob/python_workspace/Pytorch/lib/python3.7/site-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/Users/honeyeob/python_workspace/Pytorch/lib/python3.7/site-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.987500011920929\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
